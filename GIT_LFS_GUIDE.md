# ğŸ“¦ Git LFS Setup Guide cho Cognivasc

## âœ… **ÄÃ£ Setup Git LFS:**

### **ğŸ”§ Cáº¥u hÃ¬nh hoÃ n táº¥t:**
- âœ… **Git LFS initialized**
- âœ… **`.gitattributes`** created
- âœ… **Large files tracked**

### **ğŸ“ Files Ä‘Æ°á»£c track bá»Ÿi Git LFS:**
```
backend/dataset/**/*.jpg     # Dataset images
backend/dataset/**/*.png    # Dataset images
backend/dataset/**/*.jpeg   # Dataset images
backend/anemia_model.keras  # AI model (4.8MB)
*.keras                     # Model files
*.h5                        # Model files
*.hdf5                      # Model files
*.pkl                      # Pickle files
*.pickle                   # Pickle files
*.joblib                   # Joblib files
*.ipynb                    # Jupyter notebooks
```

---

## ğŸš€ **Lá»£i Ã­ch cá»§a Git LFS:**

### **1. Repository Size:**
- **TrÆ°á»›c**: Repository ráº¥t lá»›n (hÃ ng GB)
- **Sau**: Repository nhá», chá»‰ chá»©a pointers
- **Dataset**: Stored trÃªn Git LFS servers

### **2. Clone Speed:**
- **Fast clone**: Chá»‰ download pointers
- **On-demand**: Download files khi cáº§n
- **Bandwidth**: Tiáº¿t kiá»‡m bandwidth

### **3. Development:**
- **Local development**: KhÃ´ng cáº§n download dataset
- **CI/CD**: Faster builds
- **Collaboration**: Dá»… dÃ ng share code

---

## ğŸ“‹ **Git LFS Commands:**

### **Kiá»ƒm tra files Ä‘Æ°á»£c track:**
```bash
git lfs ls-files
```

### **Download specific files:**
```bash
git lfs pull --include="backend/dataset/**/*.jpg"
```

### **Download all LFS files:**
```bash
git lfs pull
```

### **Check LFS status:**
```bash
git lfs status
```

### **Migrate existing files:**
```bash
git lfs migrate import --include="*.jpg,*.png,*.keras"
```

---

## ğŸ”§ **Deploy vá»›i Git LFS:**

### **Render Deployment:**
1. **Render** sáº½ tá»± Ä‘á»™ng download LFS files
2. **Build time** cÃ³ thá»ƒ cháº­m hÆ¡n láº§n Ä‘áº§u
3. **Subsequent builds** sáº½ nhanh hÆ¡n

### **Vercel Deployment:**
1. **Vercel** há»— trá»£ Git LFS
2. **Automatic download** during build
3. **Caching** cho subsequent builds

### **Local Development:**
```bash
# Clone repository
git clone <repo-url>
cd Cognivasc

# Download LFS files (náº¿u cáº§n)
git lfs pull

# Hoáº·c download specific files
git lfs pull --include="backend/anemia_model.keras"
```

---

## âš ï¸ **LÆ°u Ã½ quan trá»ng:**

### **1. GitHub LFS Limits:**
- **Free tier**: 1GB storage, 1GB bandwidth/month
- **Paid plans**: Higher limits
- **Dataset size**: CÃ³ thá»ƒ vÆ°á»£t quÃ¡ free limit

### **2. Alternative Storage:**
- **Google Drive**: Upload dataset
- **AWS S3**: Cloud storage
- **Dropbox**: File sharing
- **OneDrive**: Microsoft storage

### **3. Production Deploy:**
- **Model file**: Cáº§n download `anemia_model.keras`
- **Dataset**: KhÃ´ng cáº§n cho production
- **Optimization**: Chá»‰ download model file

---

## ğŸ¯ **Recommended Workflow:**

### **Development:**
```bash
# Clone without LFS files
git clone <repo-url>
cd Cognivasc

# Download only model file
git lfs pull --include="backend/anemia_model.keras"
```

### **Production Deploy:**
```bash
# Render sáº½ tá»± Ä‘á»™ng download model
# Dataset khÃ´ng cáº§n thiáº¿t cho production
```

### **Research/Retraining:**
```bash
# Download full dataset
git lfs pull
```

---

## ğŸ“Š **File Size Comparison:**

| File Type | Without LFS | With LFS |
|-----------|-------------|----------|
| **Repository** | ~2GB | ~50MB |
| **Clone Time** | 10-15 min | 1-2 min |
| **Bandwidth** | High | Low |
| **Storage** | Local | LFS Server |

---

## ğŸš€ **Next Steps:**

### **1. Commit LFS setup:**
```bash
git add .gitattributes
git commit -m "Setup: Configure Git LFS for large files"
git push origin main
```

### **2. Test LFS:**
```bash
# Check LFS status
git lfs status

# Verify files are tracked
git lfs ls-files
```

### **3. Deploy:**
- **Render**: Sáº½ tá»± Ä‘á»™ng handle LFS
- **Vercel**: Sáº½ download model file
- **Local**: Chá»‰ download khi cáº§n

**Git LFS Ä‘Ã£ Ä‘Æ°á»£c setup thÃ nh cÃ´ng! Repository giá» Ä‘Ã¢y nháº¹ vÃ  nhanh hÆ¡n!** ğŸ‰
